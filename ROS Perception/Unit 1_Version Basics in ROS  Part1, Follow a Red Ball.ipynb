{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this unit you will start using cameras in ROS and use the cmvison package for blob tracking. Once you get the hang of it then in Unit2 you will go deeper in how this blob tracking is done and how the image can be processed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basically, you are going to learn how to build the example of the previous unit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First image from a Robot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll. Pitch and Yaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its time to start working, so here you have the MiralRobot in a nice room environment with a RedCricket ball.\n",
    "<br>\n",
    "Mira is a three Degrees of freedom robot that turns its head in a Roll Pitch Yaw Movement, very easy fro camera movement. So its the perfect robot for this introduction to image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/C1.png\" width=\"380\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In miras case, the axis are slightly different, more in the robotics fashion than in the aerospace way (which is inverted):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/C2.png\" width=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also have at you disposal a script for autonomously move the cricket ball around. So, lets move the ball firstly."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "roslaunch blob_tracking move_ball_keyboard.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can move the ball around by just pressing keys in the keyboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are going to see what the robot Mira is seeing. For that, you are going to use a ROS graphical tool called *rqt_image_view* that allows to see what a camera in a robot is publishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open the tool, type the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rosrun rqt_image_view rqt_image_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then on the screen you should see the window of the *rqt_image_view* application.\n",
    "On the application, select the */mira/mira/camera1/image_raw* image topic and wait a few seconds until the image feed is established. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise U1-1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now get a hang of how to move the ball around by trying to make it appear in the Mira's view. Once it is on the view of the Mira robot, you can close the program of WebShell #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob tracking with OpenCV and python part 1, colour encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what you are going to do is create a program that can track blobs of colout in the image.\n",
    "<br>\n",
    "Blobs are nothing else than areas in the image with a color encoding similar, as similar as you might define it.\n",
    "<br>\n",
    "So obviously the first step is to get a color encoding that defines the object you want to be tracked.\n",
    "<br>\n",
    "Lets do that with the red Ball shall we?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the color encoding, we are going to use another tool provided by ROS that allows to easily compute the RBG and YUV values of a target blob. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the following command in a terminal and go to the Graphical Interface Tab:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "roslaunch blob_tracking start_colour_gui.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one part and you have the RGB value of the colour on average and then you have the YUV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can close the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are going to use those values to create a configuration file, required by the blob recognition code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a package to launch all the required software to track the ball."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, create a new package named *my_blob_tracking_pkg* which depends on rospy.\n",
    "* Inside that package, create a directory named *color_filters* and put the *colors.txt* file in it. Add the values you got on the previous step, by writting the RGB in average and the YUV values like in the file below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/C3.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that there are two parts: **Colors** and **Thresholds**\n",
    "<br>\n",
    "In the **Colors**, you state:\n",
    "* The RGB value of the line around the detection, in this case The same colour as the average RGN colour detected previously, but you can put ant colour you want. Its just good practice to put the Average colour because that way you can see what blob is being detected.\n",
    "* The other two numbers are not used in this version of cmvision.\n",
    "* The Name of the blob representation, in this case RedBall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **Thresholds**, you state:\n",
    "* Essentially the Red, Green and Blue value range. In the RedBall case, Red =[from 30 to 81], Green = [from 86 to 111] and Blue = [from 178 to 253]\n",
    "* All of them are placed in the same order as the Colour List to make the correspondance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see you can put as many colours as you wish and afterwards be able to track different blobs based on these names like Green, RedBall, Teal, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob tracking with OpenCV and python part2, start blob tracking with cmvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ros package you have used for the colour setting and thta you will use for the tracking is **cmvision**, http://wiki.ros.org/cmvision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following launch file that starts the blob tracking code besed on your *colour.txt* file, connect to Miras camera and published the ball position and information in a ROS topic. You must add this launch file to the launch directorey of your package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/C4.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you set the image topic from which the RGB data will be extracted:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<arg name=\"rgb_raw_image_topic\" default=\"/mira/mira/camera1/image_raw\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you set the path to the colour file you created through the given path or if not the default value:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<arg name=\"color_file_path\" default=\"$(find my_blob_tracking_pkg)/color_files/colors.txt\"/>\n",
    "<!-- Location of the cmvision color file -->\n",
    "  <param name=\"cmvision/color_file\" type=\"string\" value=\"$(arg color_file_path)\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you launch the cmvision node that will make the blob tracking based on the image topic given:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<node name=\"cmvision\" pkg=\"cmvision\" type=\"cmvision\" args=\"image:=$(arg rgb_raw_image_topic)\" output=\"screen\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other parameters are irrelevant fro this course."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "roslaunch my_blob_tracking_pkg my_mira_cmvision_tc.lanch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you see the error *libdc 1394 error: Failed to initialze libdc 1394 do not worry. Everything is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should then have blob information published in the */blobs* topic. Let's check what is published in that topic."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rostopic list | grep /blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should show the topic */blobs* in the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check some info about the topic:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rostopic info /blobs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rosmsg show cmvision/Blobs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rostopic echo -n1 /blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise U1-2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mke a python script that retreives the needed information from the /blob topic to be able to:\n",
    "* Filter all the blobs except the RedBall blobs\n",
    "* Retrieve its position in 2D in the image\n",
    "* Publishes a Twist topic named /mira/commands/velocity, that will be used to move miras head to follow the red ball around in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File_name: *track_color.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import rospy\n",
    "from geometry_msgs.msgs import Twist\n",
    "from cmvision.msg import Blobs, Blob\n",
    "\n",
    "#global\n",
    "turn = 0.0 #turning rate\n",
    "blob_position = 0 # x position for the blob\n",
    "\n",
    "# callback function checks to see if any blobs were found then\n",
    "# loop through each and get the x position. Since the camera\n",
    "# will sometimes find many blobs in the same object we just\n",
    "# average all the x values. You could also just take the first \n",
    "# one if you are sure you will only have one blob.\n",
    "#\n",
    "# This doesn't use multiple blobs but if are tracking serval \n",
    "# objects you need to check the /data.blobs.color topic for\n",
    "# the color tag you put in your colors.txt file.\n",
    "#\n",
    "# after we have the x value we just make the robot turn to\n",
    "# keep it in the center of the image.\n",
    "\n",
    "def callback(data):\n",
    "    global turn\n",
    "    global blob_position\n",
    "    \n",
    "    if(len(data.blobs)):\n",
    "        \n",
    "        for obj in data.blobs:\n",
    "            if obj.name == \"RedBall\":\n",
    "                rospy.loginfo(\"Blob <\"+str(obj.name)+\"> Detected!\")\n",
    "                blob_position = obj.x\n",
    "                \n",
    "                rospy.loginfo(\"blob is at %s\" %blob_position)\n",
    "                # turn right if we set off the left cliff sensor\n",
    "                if(blob_position > 220):\n",
    "                    rospy.loginfo(\"TURN RIGHT\")\n",
    "                    turn = -0.1\n",
    "                #turn left if we set off the right cliff sensor\n",
    "                if(blob_position < 180):\n",
    "                    rospy.logiofo(\"TURN LEFT\")\n",
    "                    turn = 0.1\n",
    "                \n",
    "                if(blob_position > 180 and blob_position < 220):\n",
    "                    rospy.loginfo(\"CENTERED\")\n",
    "                    turn = 0.0\n",
    "                    \n",
    "    else:\n",
    "        turn = 0.0\n",
    "        \n",
    "def run():\n",
    "    rospy.init_node(\"track_blob_color_node\", log_level = rospy.WARN)\n",
    "    global blob_position\n",
    "    # publish twist messages to /cmd_vel\n",
    "    pub = rospy.Publisher('/mira/commands/velocity', Twist, queue_size=1)\n",
    "    \n",
    "    #subscribe to the robot sensor state\n",
    "    rospy.Subscriber(\"/blobs\", Blobs, callback)\n",
    "    \n",
    "    global turn\n",
    "    twist = Twist()\n",
    "    \n",
    "    while not rospy.is_shutdown():\n",
    "        \n",
    "        #turn if we hit the line\n",
    "        if (turn != 0.0):\n",
    "            str = \"Turning %s\" %turn\n",
    "            rospy.loginfo(str)\n",
    "            twist.linear.x=0.0; twist.linear.y = 0; twist.linear.z = 0\n",
    "            twist.angular.x=0; twist.angular.y=0; twist.angular.z=turn\n",
    "            turn = 0.0\n",
    "            \n",
    "            #straight otherwise\n",
    "        else:\n",
    "            str = \"Straight %s\" %turn\n",
    "            rospy.loginfo(str)\n",
    "            twist.linear.x=0.0; twist.linear.y = 0; twist.linear.z = 0\n",
    "            twist.angular.x=0; twist.angular.y=0; twist.angular.z= 0\n",
    "            \n",
    "        #send the message and delay\n",
    "        pub.publish(twist)\n",
    "        blob_position = 0\n",
    "        rospy.sleep(0.1)\n",
    "        \n",
    "\n",
    "if __name__ = '__main__':\n",
    "    try:\n",
    "        run()\n",
    "    except ropy.ROSInterruptException: pass\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise U1-3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a python script that retrelves the needed information from the */mira/commands/velovity* topic to be able to:\n",
    "* Make mira move its head to so that the red ball is in the center of the image all the time.\n",
    "* Move the ball using the keyboard program we showed to you above and really check that the head of the robot is moving to achieve that the red ball is always at the middle of the screen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you dont quite understand how to move MirasHead, we Highly recommand you to do the courses in TF, URDF and Controllers to have a full understanding of what is going on and how Mira Works.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import time\n",
    "import rospy\n",
    "from math import pi, sin, cos, acos\n",
    "import random\n",
    "from std_msgs.msg import Float64\n",
    "from sensor_msg.msg import JointState\n",
    "from geometry_msgs.msg import Twist\n",
    "\"\"\"\n",
    "Topic To Write on:\n",
    "type: std_msgs/Float64\n",
    "/mira/pitch_joint_position_controller/command\n",
    "/mira/roll_joint_position_controller/command\n",
    "/mira/yaw_joint_position_controller/command\n",
    "\"\"\"\n",
    "\n",
    "class MiraBlobTracker(object):\n",
    "    def __init__(self):\n",
    "        rospy.loginfo(\"Mira JointMover Initialising...\")\n",
    "        self.pub_mira_roll_joint_position = rospy.Publisher('/mira/roll_joint_position_controller/command',\n",
    "                                                           Float64,\n",
    "                                                           queue_size=1)\n",
    "        self.pub_mira_pitch_joint_position = rospy.Publisher('/mira/pitch_joint_position_controller/command',\n",
    "                                                           Float64,\n",
    "                                                           queue_size=1)\n",
    "        self.pub_mira_yaw_joint_position = rospy.Publisher('/mira/yaw_joint_position_controller/command',\n",
    "                                                           Float64,\n",
    "                                                           queue_size=1)\n",
    "        joint_states_topic_name = \"/mira/joint_states\"\n",
    "        rospy.Subscriber(joint_states_topic_name, JointState, self.mira_joints_callback)\n",
    "        mira_joints_data = None\n",
    "        while mira_joints_data is None:\n",
    "            try:\n",
    "                mira_joints_data = rospy.wait_for_message(joint_state_topic_name, JointState, timeout = 5)\n",
    "            except:\n",
    "                rospy.logwarn(\"Time out\" + str(joint_states_topic_name))\n",
    "                pass\n",
    "            \n",
    "            self.mira_joint_dictionary = dict(zip(mira_joints_data.name, mira_joints_data.position))\n",
    "            print self.mira_joint_dictionary\n",
    "            rospy.Subscriber('/mira/command/velocity', Twist, self.blob_info_callback)\n",
    "            \n",
    "    def blob_info_callback(self, msg):\n",
    "        rospy.loginfo(\"Blob info Detected==>\" + str(msg.angular.z))\n",
    "        turn_value = msg.angular.z\n",
    "        yaw_actual_pos = self.mira_joint_dictionary.get(\"yaw_joint\")\n",
    "        next_value = yaw_actual_pos + turn_value\n",
    "        rospy.loginfo(\"Move Head to Blob==>\" + str(next_value))\n",
    "        #self.move_mira_yaw_joint(position = next_value)\n",
    "        self.move_mira_all_joints(roll = 0.0, pitch = 0.0, yaw = next_value)\n",
    "        \n",
    "    def move_mira_all_joints(self, roll, pitch, yaw):\n",
    "        angle_roll = Float64()\n",
    "        angle_roll.data = roll\n",
    "        angle_pitch = Float64()\n",
    "        angle_pitch.data = pitch\n",
    "        angle_yaw = Float64()\n",
    "        angle_yaw.data = yaw\n",
    "        self.pub_mira_roll_joint_position.publish(angle_roll)\n",
    "        self.pub_mira_pitch_joint_position.publish(angle_pitch)\n",
    "        self.pub_mira_yaw_joint_position.publish(angle_yaw)\n",
    "        \n",
    "    def move_mira_roll_joint(self, position):\n",
    "        \"\"\"\n",
    "        limits radians: lower=\"-0.2\" upper=\"0.2\"\n",
    "        :param position:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        angle = Float64()\n",
    "        angle.data = position\n",
    "        self.pub_mira_roll_joint_position_publish(angle)\n",
    "        \n",
    "    def move_mira_pitch_joint(self, position):\n",
    "        \"\"\"\n",
    "        limits radians: lower=\"0\" upper=\"0.44\"\n",
    "        :param position:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        angle = Float64()\n",
    "        angle.data = position\n",
    "        self.pub_mira_pitch_joint_position_publish(angle)\n",
    "        \n",
    "    def move_mira_yaw_joint(self, position):\n",
    "        \"\"\"\n",
    "        limits : continuous, no limits\n",
    "        :param position:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        angle = Float64()\n",
    "        angle.data = position\n",
    "        self.pub_mira_yaw_joint_position_publish(angle)\n",
    "        \n",
    "    def mira_joints_callback(self, msg):\n",
    "        \"\"\"\n",
    "        sensor_msgs/JointState\n",
    "        std_msg/Header header\n",
    "        uint32 seq\n",
    "        time stamp\n",
    "        string frame_id\n",
    "        string[] name\n",
    "        float64[] position\n",
    "        float64[] velocity\n",
    "        float64[] effort\n",
    "        \n",
    "        :param msg:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.mira_joint_dictionary = dict(zip(msg.name, msg.position))\n",
    "       \n",
    "    def mira_check_joint_value(self, joint_name, value, error = 0.1):\n",
    "        \"\"\"\n",
    "        Check the joint by name 'pitch_joint', 'roll_joint', 'yaw_joint' is near the value given\n",
    "        :param value:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # at the end of this scentence, some values are missed...\n",
    "        similar = self.mira_joint_dictionary.get(joint_name) >= (value - error) and self.mira_joint_dictionary.get(joint_name) <= (value)\n",
    "        \n",
    "        return similar\n",
    "    \n",
    "    def convert_angle_to_unitary(self, angle):\n",
    "        \"\"\"\n",
    "        Remove complete revolutions from angel and converts to positive equivalent\n",
    "        if the angle is negative\n",
    "        :param angle: Has to be in radians\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert to angle between[0,360]\n",
    "        complete_rev = 2 * pi\n",
    "        mod_angle = int(angle / complete_rev)\n",
    "        clean_angle = angle - mod_angle * complete_rev\n",
    "        # Convert Negative angles to their corresponding positive values\n",
    "        if clean_angle < 0:\n",
    "            clean_angle += 2 * pi \n",
    "        \n",
    "        return clean_angle\n",
    "    \n",
    "    def assertAlmostEqualAngles(self, x, y):\n",
    "        c2 = (six(x) - sin(y)) ** 2 + (cos(x) - cos(y)) ** 2\n",
    "        angle_diff = acos((2.0 - c2) / 2.0)\n",
    "        return angle_diff\n",
    "    \n",
    "    def mira_check_continuous_joint_value(self, joint_name, value, error = 0.1):\n",
    "        \"\"\"\n",
    "        Check the joint by name 'pitch_joint', 'roll_joint', 'yaw_joint' is near the value fiven \n",
    "        We have to conver the joint values removing whole revolutions and converting negative versions\n",
    "        of the same angle\n",
    "        :param value:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        joint_reading = self.mira_joint_dictionary.get(joint_name)\n",
    "        clean_joint_reading = self.convert_angle_to_unitary(angle=joint_reading)\n",
    "        clean_value = self.convert_angle_to_unitary(angle=value)\n",
    "        \n",
    "        dif_angles = self.assertAlmostEqualAngles(clean_joint_reading, clean_value)\n",
    "        similar = dif_angles <= error\n",
    "        \n",
    "        return similar\n",
    "    \n",
    "    def mira_movement_look(self, roll, pitch, yaw):\n",
    "        \"\"\"\n",
    "        Make Mira look down\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        check_rate = 5.0\n",
    "        position_roll = roll\n",
    "        position_pitch = pitch\n",
    "        position_yaw = yaw\n",
    "        \n",
    "        similar_roll =  False\n",
    "        similar_pitch =  False\n",
    "        similar_yaw =  False\n",
    "        rate = rospy.Rate(check_rate)\n",
    "        while not (similar_roll and similar_pitch and similar_yaw):\n",
    "            self.move_mira_all_jointsposition_roll, position_pitch, position_yaw)\n",
    "            similar_roll = self.mira_check_continuous_joint_value(joint_name=\"roll_joint\", value=position_roll)\n",
    "            similar_pitch = self.mira_check_continuous_joint_value(joint_name=\"pitch_joint\", value=position_pitch)\n",
    "            similar_yaw = self.mira_check_continuous_joint_value(joint_name=\"yaw_joint\", value=position_yaw)\n",
    "        \n",
    "    def search_for_blob_loop(self):\n",
    "        \"\"\"\n",
    "        Execute movements in a random way\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        rospy.loginfo(\"Hearing Blobs Moving Mira...\")\n",
    "        rospy.spin()\n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    rospy.init_node('mira_move_head_node', anonymous=True)\n",
    "    mira_jointmover_object = MiraBlobTracker()\n",
    "    mira_jointmover_object.search_for_blob_loop()  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise U1-4**\n",
    "* Mira can track the ball in 3D space, that is not only moving the yaw axis but also the roll and pitch. This way the ball will be centered no matter where it goes. Remember that you can move the ball UP and DOWN by pressing \"T\" and \"B\" keys or stop applying upward force with the \"G\".\n",
    "* Make mira shake its head when the ball gose too far. Use the area variable for that.\n",
    "* Create a searching patern for Mira when it losess track of the ball."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise U1-5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the scripts of U1-2 and U1-3 so that:\n",
    "* Mira can Track various objects at the same time\n",
    "* To spawn new objects just spawn them though the **spawn_robot_tools** installed in system. If you don't quite understand them, please do the courses in TF or URDF creation to understand how this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations, you now can track anything with colour, continue to the next unit to go a bit deeper in OpenCV in ROS and learn how to navigate following a line drawned on the ground.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
